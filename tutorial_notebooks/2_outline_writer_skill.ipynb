{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skill Implementation: Article Outline Writer\n",
    "\n",
    "We'll start building our Research Writing Assistant by implementing a Skill to generate article **outlines**. \n",
    "\n",
    "By asking an LLM to generate the outline of an article, rather than an article directly, we're really asking it to begin the writing process with a plan\n",
    "\n",
    "Let's get set up to build a Skill in Council."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from council.skills import SkillBase\n",
    "from council.contexts import ChatMessage, ChainContext\n",
    "from council.runners import Budget\n",
    "from council.llm import LLMBase, LLMMessage\n",
    "\n",
    "from string import Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we'll do is define **prompts** for this **Skill**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an expert research writer and editor. \n",
    "Your role is to create and refine the outlines of research articles in markdown format.\"\"\"\n",
    "\n",
    "main_prompt_template = Template(\"\"\"\n",
    "# Task Description\n",
    "Your task is to write or revise the outline of a research article.\n",
    "First consider the CONVERSATION HISTORY, ARTICLE OUTLINE, and COMMENTS.\n",
    "Then consider the INSTRUCTIONS and write a NEW OR IMPROVED OUTLINE for the article.\n",
    "Always write the outline in markdown using appropriate section headers.\n",
    "\n",
    "## CONVERSATION HISTORY\n",
    "$conversation_history\n",
    "\n",
    "## ARTICLE OUTLINE\n",
    "$outline\n",
    "\n",
    "## INSTRUCTIONS\n",
    "$instructions\n",
    "\n",
    "## NEW OR IMPROVED OUTLINE\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of things to notice here. First, we're using Python's built-in string **Templates** for main prompts. Templates are perfect for building prompts with substitution variables. These variables will be substituted at execution time using information from the **ChainContext** - structured information that is made available to Chains when they're invoked by a Controller (we will learn more about Controllers later!)\n",
    "\n",
    "For now, it's just important to see that our intention with this prompt is that we want to generate or edit a research article outline based on:\n",
    "- conversation history\n",
    "- an existing / previously generated outline\n",
    "- other specific instructions\n",
    "\n",
    "Next, let's define the **OutlineWriterSkill**.\n",
    "\n",
    "We'll begin by extending the `SkillBase` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlineWriterSkill(SkillBase):\n",
    "    \"\"\"Write or revise the outline of an article.\"\"\"\n",
    "\n",
    "    def __init__(self, llm: LLMBase):\n",
    "        \"\"\"Build a new OutlineWriterSkill.\"\"\"\n",
    "        \n",
    "        super().__init__(name=\"OutlineWriterSkill\")\n",
    "\n",
    "        self.llm = llm\n",
    "        self.system_prompt = \"You are an expert...\"\n",
    "        self.main_prompt_template = Template(\"# Task Description ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll implement the skill's `execute` funciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(self, context: ChainContext, _budget: Budget) -> ChatMessage:\n",
    "    \"\"\"Execute `OutlineWriterSkill`.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll want to read the conversation history from the `context`, since our prompt template is expecting to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = [\n",
    "    f\"{m.kind}: {m.message}\" for m in context.messages\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we want to get both the instructions and the article outline (if it exists) from the `context`. Unlike the conversation history, which is always managed automatically by Council, the instructions and article outline will be managed by a custom defined **Controller**. When we build our Controller, we will see how to manage state for Chains and Skills such that they can be invoked with data.\n",
    "\n",
    "Get the instructions. \n",
    "\n",
    "This code assumes that the OutlineWriterSkill will be invoked with an `intial_state` where the `message` field is an instruction for the skill, e.g.: \"*Update the outline to include a section on environmental policy.*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = context.last_message.message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the outline.\n",
    "\n",
    "This code assumes that the skill will be invoked with an `initial_state` that includes 'outline' as a key in the `data` field. If the outline doesn't already exist, `context.last_message.data['outline']` will return `None`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline = context.last_message.data['outline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have `conversation_history`, `instructions`, and `outline` populated, we just need to fill in the skill's main prompt template and post a chat request to our LLM instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create the main LLM prompt by substituting variables\n",
    "main_prompt = self.main_prompt_template.substitute(\n",
    "    conversation_history=conversation_history,\n",
    "    instructions=instructions,\n",
    "    outline=outline\n",
    ")\n",
    "\n",
    "# Package messages for the LLM call\n",
    "messages_to_llm = [\n",
    "    LLMMessage.system_message(self.system_prompt),\n",
    "    LLMMessage.assistant_message(\n",
    "        main_prompt\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Send messages to LLM\n",
    "llm_response = self.llm.post_chat_request(messages=messages_to_llm)[0]\n",
    "\n",
    "# Format the Skill response\n",
    "return ChatMessage.skill(\n",
    "    source=self.name,\n",
    "    message=\"I've edited the outline and placed the response in the 'data' field.\",\n",
    "    data={'outline': llm_response, 'instructions': instructions},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, here is the entire OutlineWriterSkill implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlineWriterSkill(SkillBase):\n",
    "    \"\"\"Write or revise the outline of an article.\"\"\"\n",
    "\n",
    "    def __init__(self, llm: LLMBase):\n",
    "        \"\"\"Build a new OutlineWriterSkill.\"\"\"\n",
    "        super().__init__(name=\"OutlineWriterSkill\")\n",
    "        self.llm = llm\n",
    "\n",
    "        self.system_prompt = \"\"\"You are an expert research writer and editor. \n",
    "        Your role is to create and refine the outlines of research articles in markdown format.\"\"\"\n",
    "\n",
    "        self.main_prompt_template = Template(\"\"\"\n",
    "        # Task Description\n",
    "        Your task is to write or revise the outline of a research article.\n",
    "        First consider the CONVERSATION HISTORY, ARTICLE OUTLINE, and COMMENTS.\n",
    "        Then consider the INSTRUCTIONS and write a NEW OR IMPROVED OUTLINE for the article.\n",
    "        Always write the outline in markdown using appropriate section headers.\n",
    "\n",
    "        ## CONVERSATION HISTORY\n",
    "        $conversation_history\n",
    "\n",
    "        ## ARTICLE OUTLINE\n",
    "        $article_outline\n",
    "\n",
    "        ## INSTRUCTIONS\n",
    "        $instructions\n",
    "\n",
    "        ## NEW OR IMPROVED OUTLINE\n",
    "        \"\"\")\n",
    "\n",
    "    def execute(self, context: ChainContext, _budget: Budget) -> ChatMessage:\n",
    "        \"\"\"Execute `OutlineWriterSkill`.\"\"\"\n",
    "\n",
    "        # Get the conversation history from the context\n",
    "        conversation_history = [\n",
    "            f\"{m.kind}: {m.message}\" for m in context.messages\n",
    "        ]\n",
    "\n",
    "        # Get the outline from the context.\n",
    "        outline = context.last_message.data['outline']\n",
    "\n",
    "        # Get the instructions.\n",
    "        instructions = context.last_message.message\n",
    "        \n",
    "        # Create the main LLM prompt by substituting variables\n",
    "        main_prompt = self.main_prompt_template.substitute(\n",
    "            conversation_history=conversation_history,\n",
    "            outline=outline,\n",
    "            instructions=instructions\n",
    "        )\n",
    "\n",
    "        # Package messages for the LLM call\n",
    "        messages_to_llm = [\n",
    "            LLMMessage.system_message(self.system_prompt),\n",
    "            LLMMessage.assistant_message(\n",
    "                main_prompt\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        # Send messages to LLM\n",
    "        llm_response = self.llm.post_chat_request(messages=messages_to_llm)[0]\n",
    "\n",
    "        # Format the Skill response\n",
    "        return ChatMessage.skill(\n",
    "            source=self.name,\n",
    "            message=\"I've edited the outline and placed the response in the 'data' field.\",\n",
    "            data={'outline': llm_response, 'instructions': instructions},\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part, we will define one more skill: **ArticleSectionWriterSkill**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "writing-assistant-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
